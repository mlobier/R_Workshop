---
title       : Introduction to R Workshop 
subtitle    : Session 1
author      : Muriel Lobier
job         : 
framework   : io2012        # {io2012, html5slides, shower, dzslides, ...}
highlighter : highlight.js  # {highlight.js, prettify, highlight}
hitheme     : tomorrow      # 
widgets     : [mathjax, quiz, bootstrap]           # {mathjax, quiz, bootstrap}
mode        : selfcontained # {standalone, draft}
knit        : slidify::knit2slides
---

## Introduction to R for data analysis and visualization

### Workshop agenda

* Scientific data analysis should: 
  * be reproducible 
    * by me
    * by others (if given my code and data)
  * follow rigorous statistical standards
  * use open tools 
  
  
* R is a great way to achieve this


--- .class #id 

## Introduction to R for data analysis and visualization

### Overarching objective: 
* Be able to use R and R-studio to:
  * establish a reproducible and documented data-analysis pipeline

###  Specific Learning goals:
* How to structure a data analysis project
* How to import, clean up and transform data
* How to visualize data and make publication ready figures
* How to run simple inferential statistical analyses
* How to run less-simple inferential statistical analyses

--- .class #id 

## Introduction to R for data analysis and visualization

### Insctructor's philosophy and priors:

* Learning the most efficient tools first is more ... efficient
* Learning to solve problems is more efficient than:
  * reading code written by someone else to solve a fake problem
  * listening to the instructor drone on and on and make bad jokes
* The tidyverse and ggplot are awesome

### What this workshop is not:
* A complete overview of all that R can do
* An R programming course
 

---

## Session 1 - Learning goals

* Using R-Studio
* R scripts
* How to structure a data analysis project
* Importing Data
* What is Tidy data
* Transforming and restructuring data

---

## R-studio

So let's start by opening R-Studio !!

```{r echo=FALSE, eval=FALSE}
Here we all open R-Studio

We go through the interface together:
  Scripts / Console / ENvironment / History / Files and packages

People should have gone thru a quick online tutorial before so should go fast.
```

---

## R-studio and R-Notebooks

Now let's create a notebook.
Notebooks are great because you can:
* mix text and code in the same document
* execute blocks of code sequentially 

```{r echo=FALSE, eval=FALSE}
We create an R notebook

```
<iframe src='./assets/img/session_1_RNotebook.png'>
</iframe> 

--- &twocol

## Problem to solve Nb 1

We have acquired data on a Posner-like stimulus detection and discrimination task. 
*** =left

<iframe src='./assets/img/session_1_paradigm.png'>
</iframe> 

*** =right
Independent variables: 
* Attention :
  * Left / Right
* Stimulus contrast :
  * Low / High
* Stimulus validity:
  * Valid / Invalid
  
Dependent variables:
* RT
* Detection rate
* Discrimination rate

---

## The problem we want to solve

Go from this:

<iframe src='./assets/img/session_1_folders.png'>
</iframe> 



---

## The problem we want to solve

To this:

<iframe src='./assets/img/session_1_final_objective.svg'>
</iframe> 

---
## Step 1: create a project folder structure

Project directories should be organized consistently and methodically. My preferred structure would be:

project_name/ (root directory)
* name_of_analysis.Rmd (Rnotebook with main analysis code)
* R/ (fproject-specific R function files)
* data/ (original data - READ ONLY)
* figs/ (figures generated by my code)
* output/ (processed or simulated data, other non-final output )

**Create your own project directory structure now**

---

## Step 2: create R Notebook for our analysis

Notebooks are great because you can:
* combine text and code in the same document
* execute blocks of code sequentially to build your analysis step by step
* save the ouput as:
  * a notebook file .nb.html
  * a browser-friendly html file (or pdf, word....)

```{r echo=FALSE, eval=FALSE}
Everybody goes to Create File, new R note Book

```
<iframe src='./assets/img/session_1_RNotebook.png'>
</iframe> 

---

## Step 2: create R Notebook for our analysis

* **Save your R notebook in your project root directory**

* Remember to modify the title of the notebook header to a descriptive title

* You can 
  * execute a chunk by clicking the *Run* button within the chunk or by placing your cursor inside it and pressing *Ctrl+Shift+Enter*. 
  * add a new chunk by clicking the *Insert Chunk* button on the toolbar or by pressing *Ctrl+Alt+I*
  * preview the ouput files by pressing preview
  
* R notebooks use Markdown syntax. A helful cheatsheet is here.

---
## Step 3: Download the data

* Dowload the data from google drive to a /data/behav/ directory.

* Remember to have a different folder for each subject.

---

## Importing data


* First we load the tidyverse library

* What is tidyverse? It's **AWESOME** as you can see [here](http://tidyverse.org/)

So we first load the tidyverse library which will load most of the 'verse...
```{r}
library(tidyverse)
```

---

## Importing data

In the `R_Workshop_exercises` directory, open the `importing_csv_files.R' script.

* Carry out PART 1


---

## Importing data

In the `data\exercises\session_1` directory, there are several data files.

```{r}
list.files("data/exercises/session_1")
```

* These files can all be read by one of the following readr functions with the proper parameters:

  * `read_csv()`  -  `read_csv2()`  - `read_tsv()`  - `read_delim()`
  
1. Use the help function ? to see the difference between these functions 
2. Open the data_1.csv file with a text editor to figure our the best function 
3. Try to import data_1.csv into variable data_1 `data_1<-read_xxx()`     
4. look at the **Environment** tab in the upper right pane to see what your data looks like

---

## Importing data

* Data_1.csv is a standard *comma-separated* flat data file 
  * We can use `read_csv()` to import it
  * We **assign** the data to a variable  *data_1* using the `<-` operator
  * *data_1* should now have appeared in the top-right **Environment** pane


```{r, eval=FALSE}
data_1<-read_csv("data/Exercises/session_1/data_1.csv")

```

---



## Importing data

```{r, eval=TRUE, warning=FALSE}
data_1<-read_csv("data/Exercises/session_1/data_1.csv")
```

---

## Importing data

```{r, eval=TRUE, message=FALSE}
data_1<-read_csv("data/Exercises/session_1/data_1.csv")
```

---

## Importing data

```{r, eval=TRUE, warning=FALSE, message=FALSE}
data_1<-read_csv("data/Exercises/session_1/data_1.csv")
data_1
```

---

## Importing data - Dataframes or tibbles

```{r, eval=FALSE, echo=FALSE}
# Here we discuss the dataframe and tibble structures as well as the head() command.
```

```{r, eval=TRUE, warning=FALSE, message=FALSE}
head(data_1)
```

---

## Importing data

* Find the appropriate function to import each remaining file to a data structure
* Assign the files to names relevant to the file (i.e. data_2, etc.)
* The data is the same, so check that the data structures you obtain are in fact the same

---

## Inspecting data

* the `summary()` function can give us a quick look at our data

```{r}
summary(data_1)
```

---


## Inspecting data

* the `names()` function returns a vector of our variable names

```{r}
names(data_1)
```

---

## Inspecting data

* the `$` operator allows us to call a single variable of our dataframe/tibble

```{r}
data_1$trialNb
```

---

## Inspecting data

* the `$` operator allows us to call a single variable of our dataframe/tibble
* we can then apply a function on the output vector like the mean stimulus duration

```{r}
mean(data_1$stimDuration)
```


---

## Inspecting data

* Try computing the mean response reaction time

```{r}
mean(data_1$responseRT)
```

* What is the problem ?

---

## Inspecting data

```{r}
data_1$responseRT
```

---

## Inspecting data

```{r}
data_1$responseRT
```

```{r}
mean(data_1$responseRT, na.rm=TRUE)
```

---

## Cleaning up the data - renaming - recoding

```{r}
head(data_1)
```

---

## Cleaning up the data - renaming - recoding

```{r}
data_1[1:10,]$taskType
```

* rename a variable:
 * taskType -> Contrast
* recode the values 
  * detection -> low
  * discrimintation -> high
  
